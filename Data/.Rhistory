color = factor(Settlement))) +
geom_area(alpha = 0.4, position = "identity") +
geom_line(linewidth = 0.5) +
facet_wrap(~Dataset, nrow = 2,
labeller = as_labeller(c(
"Original" = "Hypothetical Population",
"Sampled" = "Random Sample",
"Weighted Sampled" = "Weighted",
"Resampled30" = "Bootstrap"
)))+
scale_fill_manual(name = "Settlement", values = distinct_colors) +
scale_color_manual(name = "Settlement", values = distinct_colors) +
guides(
fill = guide_legend(nrow = 1),
color = guide_legend(nrow = 1)
) +
labs(title = "Settlement SPD Comparison",
subtitle = sprintf("%s - %s (Seed %d)",
settlement_dist, bp_dist, seed),
x = "Cal BP",
y = "Probability Density") +
scale_x_reverse() +
theme_bw() +
theme(
plot.title = element_text(size = 35, face = "bold", hjust = 0.5),
plot.subtitle = element_text(size = 40, face = "bold", hjust = 0.5,
margin = margin(t = 10, b = 20)),
axis.title.x = element_text(size = 35, face = "bold", margin = margin(t = 15)),
axis.title.y = element_text(size = 35, face = "bold", margin = margin(r = 15)),
axis.text.x = element_text(size = 35, face = "bold"),
axis.text.y = element_text(size = 35, face = "bold"),
strip.text = element_text(size = 40, face = "bold"),
legend.title = element_text(size = 40, face = "bold"),
legend.text = element_text(size = 40, face="bold"),
legend.position = "bottom",
legend.box = "horizontal",
legend.margin = margin(t = 5, b = 0, l = 0, r = 0),
legend.spacing.x = unit(1.5, 'cm'),
legend.key.width = unit(1.5, "cm"),
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA),
legend.background = element_rect(fill = "white", color = NA),
panel.spacing = unit(1, "cm"),
plot.margin = margin(t = 20, r = 40, b = 20, l = 20)
)
# Define output filename with path
output_filename <- sprintf("Settlement_SPD_S%d_%s_%s.png",
seed,
settlement_dist,
bp_dist)
# Save plot
ggsave(output_filename, p, width = 30, height = 16)
return(p)
}
# Create plot for specific combination
plot <- create_settlement_plot_from_file_smooth_RM50(
seed = 50,
settlement_dist = "power_law",
bp_dist = "normal",
file_path= "/Volumes/SAMSUNG/부트스트랩 리부트/Code/1500 yrs/Calibration/CalData 1500-30/"
)
library(dplyr)
library(rcarbon)
library(ggplot2)
library(ggpubr)
library(tidyr)
library(readr)
library(patchwork)
library(zoo)
library(ggrepel)
library(ggsci)
library(ggrepel)
library(RColorBrewer)
library(purrr)
# set directory
setwd("//Users/Sejin_1/Desktop/Sejin_Git/Bootstrap/Data")
# Load published radiocarbon dates.
# Load one of the datasets: either "Yeongsanriver.csv" or "Geumriver.csv",
# depending on the target river basin.
#sampled_data <- read.csv("C14_data_Yeongsanriver.csv", , fileEncoding="cp949")
sampled_data <- read.csv("C14_data_Geumriver.csv", , fileEncoding="cp949")
# calculate weights for each settlement
weights <- sampled_data %>%
group_by(SiteCode) %>%
summarise(total_houses = unique(total_houses), count = n()) %>%
mutate(weight = total_houses / count)
# prepare bootstrap dataset
# define function for resampling
resample_data <- function(sampled_data, n_resamples, seed_rs) {
set.seed(seed_rs)
resampled_data <- data.frame()
for (resample_iter in 1:n_resamples) {
print(paste("Starting resampling iteration:", resample_iter))
# resampling by site(SiteCode)
resampled_iteration <- sampled_data %>%
group_by(SiteCode) %>%
group_modify(~ {
n_houses <- unique(.x$`total_houses`)
if (length(n_houses) == 0 || is.na(n_houses) || n_houses <= 0) {
return(NULL)
}
resampled_subset <- .x[sample(nrow(.x), n_houses, replace = TRUE), ]
resampled_subset <- resampled_subset %>%
mutate(
Resample_Iteration = resample_iter,
Sampling_Num = seq_len(n())
)
return(resampled_subset)
}) %>%
ungroup()
resampled_data <- bind_rows(resampled_data, resampled_iteration)
print(paste("Completed resampling iteration:", resample_iter))
}
return(resampled_data)
}
# resample 30 times, set seed as 1234
resampled_output <- resample_data(sampled_data, n_resamples = 30, seed_rs = 1234)
# Function to calibrate dates with errors
calibrate_dates <- function(settlement_data) {
if (nrow(settlement_data) > 0) {
calibrated <- calibrate(settlement_data$BP, errors = settlement_data$Error, timeRange = c(2600, 1200), normalised = TRUE)
return(calibrated)
}
return(NULL)
}
# Function to extract SPD info while retaining `SiteCode`
extract_spd_info_with_site <- function(cal_date, site) {
if (inherits(cal_date, "CalDates")) {
spd_result <- spd(cal_date, timeRange = c(2600, 1200), spdnormalised = FALSE)
spd_data <- data.frame(
calBP = spd_result$grid$calBP,
PrDens = spd_result$grid$PrDens,
SiteCode = site
)
return(spd_data)
}
return(NULL)
}
# Compute SPD for Sampled Data
sampled_spd_results <- sampled_data %>%
group_by(SiteCode) %>%
summarise(Calibrated_Dates = list(calibrate_dates(pick(everything()))), .groups = 'drop') %>%
mutate(SPD = map2(Calibrated_Dates, SiteCode, extract_spd_info_with_site))
# Compute SPD for Resampled Data
resampled_spd_results <- resampled_output %>%
group_by(SiteCode) %>%
summarise(Calibrated_Dates = list(calibrate_dates(pick(everything()))), .groups = 'drop') %>%
mutate(SPD = map2(Calibrated_Dates, SiteCode, extract_spd_info_with_site))
sampled_data <- read_csv(here("C14_data_Geumriver.csv", fileEncoding="cp949"))
library(here)
sampled_data <- read_csv(here("C14_data_Geumriver.csv", fileEncoding="cp949"))
sampled_data <- read_csv(here("Data",C14_data_Geumriver.csv", fileEncoding="cp949"))
sampled_data <- read_csv(here("Data","C14_data_Geumriver.csv", fileEncoding="cp949"))
# calculate weights for each settlement
weights <- sampled_data %>%
group_by(SiteCode) %>%
summarise(total_houses = unique(total_houses), count = n()) %>%
mutate(weight = total_houses / count)
sampled_data <- read.csv(here("Data", "C14_data_Geumriver.csv"), fileEncoding = "cp949")
# Load published radiocarbon dates.
# Load one of the datasets: either "Yeongsanriver.csv" or "Geumriver.csv",
# depending on the target river basin.
#sampled_data <- read.csv("C14_data_Yeongsanriver.csv", , fileEncoding="cp949")
sampled_data <- read.csv(here("Data", "C14_data_Geumriver.csv"), fileEncoding = "cp949")
# calculate weights for each settlement
weights <- sampled_data %>%
group_by(SiteCode) %>%
summarise(total_houses = unique(total_houses), count = n()) %>%
mutate(weight = total_houses / count)
# prepare bootstrap dataset
# define function for resampling
resample_data <- function(sampled_data, n_resamples, seed_rs) {
set.seed(seed_rs)
resampled_data <- data.frame()
for (resample_iter in 1:n_resamples) {
print(paste("Starting resampling iteration:", resample_iter))
# resampling by site(SiteCode)
resampled_iteration <- sampled_data %>%
group_by(SiteCode) %>%
group_modify(~ {
n_houses <- unique(.x$`total_houses`)
if (length(n_houses) == 0 || is.na(n_houses) || n_houses <= 0) {
return(NULL)
}
resampled_subset <- .x[sample(nrow(.x), n_houses, replace = TRUE), ]
resampled_subset <- resampled_subset %>%
mutate(
Resample_Iteration = resample_iter,
Sampling_Num = seq_len(n())
)
return(resampled_subset)
}) %>%
ungroup()
resampled_data <- bind_rows(resampled_data, resampled_iteration)
print(paste("Completed resampling iteration:", resample_iter))
}
return(resampled_data)
}
# resample 30 times, set seed as 1234
resampled_output <- resample_data(sampled_data, n_resamples = 30, seed_rs = 1234)
# Function to calibrate dates with errors
calibrate_dates <- function(settlement_data) {
if (nrow(settlement_data) > 0) {
calibrated <- calibrate(settlement_data$BP, errors = settlement_data$Error, timeRange = c(2600, 1200), normalised = TRUE)
return(calibrated)
}
return(NULL)
}
# Function to extract SPD info while retaining `SiteCode`
extract_spd_info_with_site <- function(cal_date, site) {
if (inherits(cal_date, "CalDates")) {
spd_result <- spd(cal_date, timeRange = c(2600, 1200), spdnormalised = FALSE)
spd_data <- data.frame(
calBP = spd_result$grid$calBP,
PrDens = spd_result$grid$PrDens,
SiteCode = site
)
return(spd_data)
}
return(NULL)
}
# Compute SPD for Sampled Data
sampled_spd_results <- sampled_data %>%
group_by(SiteCode) %>%
summarise(Calibrated_Dates = list(calibrate_dates(pick(everything()))), .groups = 'drop') %>%
mutate(SPD = map2(Calibrated_Dates, SiteCode, extract_spd_info_with_site))
# Compute SPD for Resampled Data
resampled_spd_results <- resampled_output %>%
group_by(SiteCode) %>%
summarise(Calibrated_Dates = list(calibrate_dates(pick(everything()))), .groups = 'drop') %>%
mutate(SPD = map2(Calibrated_Dates, SiteCode, extract_spd_info_with_site))
# Compute Weighted SPD using Sampled Data
weighted_spd_results <- sampled_spd_results %>%
left_join(weights, by = "SiteCode") %>%
mutate(SPD = pmap(list(SPD, weight, SiteCode), function(spd, w, site) {
if (!is.null(spd)) {
spd$PrDens <- spd$PrDens * w
spd$SiteCode <- site
}
return(spd)
}))
#drawing SPD. by settlement with 25-year rolling mean
combine_spd_per_settlement <- function(spd_results) {
bind_rows(spd_results$SPD) %>%
group_by(calBP, SiteCode) %>%
summarise(PrDens = sum(PrDens, na.rm = TRUE), .groups = 'drop') %>%
arrange(SiteCode, desc(calBP)) %>%
group_by(SiteCode) %>%
mutate(PrDens = zoo::rollmean(PrDens, k = 25, fill = "extend", align = "center")) %>%
ungroup()
}
# ✅ Aggregate SPDs for Sampled, Resampled, and Weighted
sampled_spd_total_by_settlement <- combine_spd_per_settlement(sampled_spd_results)
resampled_spd_total_by_settlement <- combine_spd_per_settlement(resampled_spd_results)
weighted_spd_total_by_settlement <- combine_spd_per_settlement(weighted_spd_results)
# ✅ Function to normalize SPDs
normalize_spd <- function(spd_df) {
total_density <- sum(spd_df$PrDens, na.rm = TRUE)
spd_df <- spd_df %>%
mutate(PrDens = PrDens / total_density)  # ✅ Normalize SPD
return(spd_df)
}
# ✅ Normalize the SPDs
sampled_spd_normalized <- normalize_spd(sampled_spd_total_by_settlement %>%
group_by(calBP) %>%
summarise(PrDens = sum(PrDens), .groups = 'drop') %>%
mutate(Dataset = "Published"))
resampled_spd_normalized <- normalize_spd(resampled_spd_total_by_settlement %>%
group_by(calBP) %>%
summarise(PrDens = sum(PrDens), .groups = 'drop') %>%
mutate(Dataset = "Bootstrap"))
weighted_spd_normalized <- normalize_spd(weighted_spd_total_by_settlement %>%
group_by(calBP) %>%
summarise(PrDens = sum(PrDens), .groups = 'drop') %>%
mutate(Dataset = "Weighted"))
total_spd_normalized <- bind_rows(sampled_spd_normalized, resampled_spd_normalized, weighted_spd_normalized)
spd_colors <- c("Published" = "#ffbb6f", "Bootstrap" = "#999999", "Weighted" = "#5e4c5f")
total_spd_normalized$Dataset <- factor(total_spd_normalized$Dataset, levels = c("Published", "Bootstrap", "Weighted"))
plot_total_spd_normalized <- ggplot(total_spd_normalized, aes(x = calBP, y = PrDens, color = Dataset, linetype = Dataset)) +
geom_line(linewidth = 1) +
scale_color_manual(values = spd_colors) +
scale_linetype_manual(values = c("Published" = "solid", "Bootstrap" = "dashed", "Weighted" = "dotdash")) +
scale_x_reverse(limits = c(2200, 1400)) +
labs(title = "Total SPD Comparison (Normalized)",
x = "cal BP", y = "Normalized SPD") +
theme_minimal(base_family = "noto") +
theme(
text = element_text(family = "noto"),
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA),
legend.position = "top",  # ✅ Move legend to the top
legend.text = element_text(size = 13, face = "bold"),
legend.title = element_blank(),
legend.key.width = unit(1, "cm"),
plot.title = element_text(size = 17, face = "bold", hjust = 0.5),
axis.text = element_text(size = 13, face = "bold"),
axis.title = element_text(size = 13, face = "bold")
)
print(plot_total_spd_normalized)
ggsave("Figure10a.png", plot_total_spd_normalized, width = 12, height = 4, dpi = 300)
normalize_preserve_shape <- function(all_spd_df) {
# Compute total SPD contribution per settlement
settlement_totals <- all_spd_df %>%
group_by(Dataset, SiteCode) %>%
summarise(Total_PrDens = sum(PrDens), .groups = 'drop') %>%
group_by(Dataset) %>%
mutate(
Dataset_Total = sum(Total_PrDens),
Target_Proportion = Total_PrDens / Dataset_Total
)
# Merge with original data and scale accordingly
normalized_spd <- all_spd_df %>%
left_join(settlement_totals %>% dplyr::select(Dataset, SiteCode, Target_Proportion),
by = c("Dataset", "SiteCode")) %>%
group_by(Dataset, SiteCode) %>%
mutate(
Adjusted_PrDens = PrDens * (Target_Proportion / sum(PrDens))
) %>%
ungroup()
return(normalized_spd)
}
# Combine all SPD datasets
all_spd_df <- bind_rows(
sampled_spd_total_by_settlement %>% mutate(Dataset = "Published"),
resampled_spd_total_by_settlement %>% mutate(Dataset = "Bootstrap"),
weighted_spd_total_by_settlement %>% mutate(Dataset = "Weighted")
)
# ✅ Normalize the SPDs
normalized_spd_df <- normalize_preserve_shape(all_spd_df)
normalized_spd_df$SiteCode <- factor(normalized_spd_df$SiteCode)
# add labels
n_settlements <- length(unique(normalized_spd_df$SiteCode))
distinct_colors <- pal_d3("category20")(n_settlements)
plot_normalized_spds <- function(dataset_name) {
df_filtered <- normalized_spd_df %>%
filter(Dataset == dataset_name)
# Find peak positions for each SiteCode for labeling
label_positions <- df_filtered %>%
group_by(SiteCode) %>%
summarise(calBP = calBP[which.max(Adjusted_PrDens)],
Adjusted_PrDens = max(Adjusted_PrDens))
ggplot(df_filtered, aes(x = calBP, y = Adjusted_PrDens, fill = factor(SiteCode), color = factor(SiteCode))) +
geom_area(alpha = 0.4, position = "identity") +
geom_line(linewidth = 0.5) +
scale_fill_manual(name = "Settlement", values = distinct_colors) +
scale_color_manual(name = "Settlement", values = distinct_colors) +
labs(title = paste(dataset_name, " dataset (rescale to 1)"),
x = "cal BP", y = "Scaled Probability Density") +
scale_x_reverse(limits = c(2200, 1400)) +
theme_minimal() +
theme(text = element_text(family = "noto"),
legend.position = "bottom",
legend.direction = "horizontal",
#legend.spacing.x = unit(0.6, "cm"),
#legend.key.size = unit(0.6, "cm"),
#legend.key.width = unit(0.6, "cm"),
legend.text = element_text(size = 30, face = "bold"),
legend.title = element_text(size = 30, face = "bold"),
plot.title = element_text(size = 30, face = "bold", hjust = 0.5),
axis.text = element_text(size = 20, face = "bold"),
axis.title.y = element_text(size = 25, face = "bold", margin = margin(r = 0)),
axis.title.x = element_text(size = 25, face = "bold")
) +
geom_text_repel(
data = label_positions,
aes(x = calBP, y = Adjusted_PrDens, label = SiteCode),
size = 11, family = "noto", fontface = "bold",
box.padding = 0.5, point.padding = 0.5,
segment.color = "black",
segment.size = 1,
max.overlaps = Inf,
force = 20
)
}
# ✅ Create plots
plot_sampled <- plot_normalized_spds("Published")
plot_resampled <- plot_normalized_spds("Bootstrap")
plot_weighted <- plot_normalized_spds("Weighted")
# Combine plots horizontally and share legend from one plot only
combined_normalized_plot <- plot_sampled + plot_resampled + plot_weighted +
plot_layout(ncol = 3, guides = "collect") &
theme(legend.position = "bottom",
legend.text = element_text(size = 30, face = "bold"),
legend.title = element_text(size = 30, face = "bold"),
legend.key.size = unit(1.5, "cm"),
legend.key.width = unit(1.5, "cm")) &
guides(fill = guide_legend(nrow = 2), color = guide_legend(nrow = 2))
print(combined_normalized_plot)
ggsave("Figures10b.png", combined_normalized_plot, width = 30, height = 12, dpi = 300, bg = "white")
# Combine plots horizontally and share legend from one plot only
combined_normalized_plot <- plot_sampled + plot_resampled + plot_weighted +
plot_layout(ncol = 3, guides = "collect") &
theme(legend.position = "bottom",
legend.text = element_text(size = 30, face = "bold"),
legend.title = element_text(size = 30, face = "bold"),
legend.key.size = unit(1.5, "cm"),
legend.key.width = unit(1.5, "cm")) &
guides(fill = guide_legend(nrow = 2), color = guide_legend(nrow = 2))
ggsave("Figures10b.png", combined_normalized_plot, width = 30, height = 12, dpi = 300, bg = "white")
# Combine plots horizontally and share legend from one plot only
combined_normalized_plot <- plot_sampled + plot_resampled + plot_weighted +
plot_layout(ncol = 3, guides = "collect") &
theme(legend.position = "bottom",
legend.text = element_text(size = 30, face = "bold"),
legend.title = element_text(size = 30, face = "bold"),
legend.key.size = unit(1.5, "cm"),
legend.key.width = unit(1.5, "cm")) &
guides(fill = guide_legend(nrow = 2), color = guide_legend(nrow = 2))
ggsave("Figures10b.png", combined_normalized_plot, width = 30, height = 12, dpi = 300, bg = "white")
library(rworldmap)
library(spatstat)
library(sf)
library(raster)
library(gridExtra)
library(rworldmap)
library(rnaturalearth)
# install.packages("spatstat.geom")  # Required for `as.owin()`
# install.packages("maptools")  # Helps with conversion
library(sp)
library(spatstat.geom)
library(gridExtra)
# Set Korea Coordinate System (EPSG:5179)
bng <- CRS("+init=EPSG:5179")
skorea <- getMap(resolution = "high")
# Download and load shapefile for administrative boundaries of Korea
# you can download shapefile here: http://www.gisdeveloper.co.kr/?p=2332
map_korea_total <- st_read("sig_20230729/sig.shp", options = "ENCODING=CP949")
# Download and load shapefile for administrative boundaries of Korea
# you can download shapefile here: http://www.gisdeveloper.co.kr/download/admin_shp/sig_20230729.zip
map_korea_total <- st_read("sig_20230729/sig.shp", options = "ENCODING=CP949")
st_crs(map_korea_total) <- st_crs(5179)  # Korea's Unified Coordinate System
map_korea_total$SIG_KOR_NM <- enc2utf8(map_korea_total$SIG_KOR_NM)
# 2) Geum river basin
sig_cd_values <- c("43110", "36110", "43111", "43112", "43113","43114",  "30140", "30170", "30200","30230", "43710")
map_korea_filtered <- map_korea_total %>%
filter(SIG_CD %in% sig_cd_values)
# Merge multiple geometries into a single polygon. Convert sf to SpatioPolygons and then to owin
map_korea_filtered <- st_union(map_korea_filtered)
map_korea_sp <- as(map_korea_filtered, "Spatial")
map_korea_spatstat <- as.owin(map_korea_filtered)
#------------------------------------------------------------------------
#------------ step 2. prepare radiocarbon dates for spatial analysis
#------------------------------------------------------------------------
# Convert sampled_data to an sf object with initial CRS as WGS 84 (EPSG:4326)
sampled_data_sf <- st_as_sf(sampled_data, coords = c("x", "y"), crs = 4326)
# Transform to the same CRS as map_korea_filtered (EPSG:5179)
sampled_data_sf <- st_transform(sampled_data_sf, crs = 5179)
unique_sampled_data <- sampled_data %>% distinct(SiteCode, .keep_all = TRUE)
# Convert the unique data to an sf object
unique_sampled_data_sf <- st_as_sf(
unique_sampled_data,
coords = c("x", "y"),
crs = 4326  # WGS 84
) %>%
st_transform(crs = 5179)
# Plot with non-overlapping text labels for unique points
ggplot() +
geom_sf(data = map_korea_filtered, fill = "lightgray", color = "black", alpha = 0.7) +
geom_sf(data = unique_sampled_data_sf, color = "red", size = 3, alpha = 0.8) +
geom_text_repel(data = unique_sampled_data_sf, aes(label = SiteCode, geometry = geometry),
stat = "sf_coordinates", size = 2, family = "nanumgothic") +
labs(title = "Sampled Data Points with Labels on Map", x = "Longitude", y = "Latitude") +
theme_minimal(base_family = "nanumgothic") +
coord_sf(expand = FALSE) +
theme(panel.grid.major = element_line(color = "gray", linetype = "dashed"),
panel.grid.minor = element_line(color = "gray90", linetype = "dashed"))
resampled_output_sf <- st_as_sf(
resampled_output,
coords = c("x", "y"),
crs = 4326  # WGS 84
)
# Transform to the same CRS as map_korea_filtered (EPSG:5179)
resampled_output_sf <- st_transform(resampled_output_sf, crs = 5179)
# Calibrate resampled data and perform stkde analysis for published data
calibrated_sampled <- calibrate(x = sampled_data$BP,  errors = sampled_data$Error,
timeRange = c(2600, 1200), normalised = FALSE)
stkde_sampled <- stkde( x = calibrated_sampled, coords = st_coordinates(sampled_data_sf),
win = map_korea_spatstat, sbw=5000, cellres = 50, focalyears = seq(2100, 1400, -100),
tbw = 50, timeRange = c(2400, 1400), dateRange = range(filtered_sampled_data$BP, na.rm = TRUE))
# Define the file path for the output image
output_file <- "Figure 10c_published data.png"
png(filename = output_file, width = 6000, height = 1000, res = 500)
par(mfrow = c(1, 6), mar = c(0.5, 0, 2, 0.5), oma = c(0, 0, 3, 0), font = 2)
#plot(stkde_sampled, 2100, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 2100")
plot(stkde_sampled, 2000, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 2000")
plot(stkde_sampled, 1900, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1900")
plot(stkde_sampled, 1800, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1800")
plot(stkde_sampled, 1700, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1700")
plot(stkde_sampled, 1600, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1600")
plot(stkde_sampled, 1500, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1500")
mtext("KDE - Published data", outer = TRUE, cex = 1.2, font = 2, line = 1)
dev.off()
# Calibrate resampled data and perform stkde analysis for resampled data
calibrated_resampled <- calibrate(x = resampled_output$BP, errors = resampled_output$Error,
timeRange = c(2400, 1400), normalised = FALSE)
stkde_resampled <- stkde( x = calibrated_resampled, coords = st_coordinates(resampled_output_sf),
win = map_korea_spatstat, sbw = 5000, cellres = 50, focalyears = seq(2100, 1400, -100),
tbw = 50, timeRange = c(2400, 1400), dateRange = range(resampled_output$BP, na.rm = TRUE))
# Plot the density for each focal year
#focal_years <- seq(2100, 1500, -100)
output_file_resampled <- "Figure 10c_Bootstrap data.png"
png(filename = output_file_resampled, width = 6000, height = 1000, res = 500)
par(mfrow = c(1, 6), mar = c(0.5, 0, 2, 0.5), oma = c(0, 0, 3, 0), font = 2)
#plot(stkde_resampled, 2100, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 2100")
plot(stkde_resampled, 2000, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 2000")
plot(stkde_resampled, 1900, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1900")
plot(stkde_resampled, 1800, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1800")
plot(stkde_resampled, 1700, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1700")
plot(stkde_resampled, 1600, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1600")
plot(stkde_resampled, 1500, type = "focal", cex.main = 1.8, cex.axis = 1.2, cex.lab = 1.2, main = "Year 1500")
mtext("KDE - Bootstrap data", outer = TRUE, cex = 1.3, font = 2, line = 1)
dev.off()
